{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kona0107/Python_Projects/blob/main/%EA%B8%B0%EC%83%81%EC%B2%AD_api_%ED%98%B8%EC%B6%9C(2015_2022).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F7WuuuPpfeY"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "# 엑셀 파일 읽기\n",
        "file_path = r'DMS_관측소_매핑.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# DMS CODE와 기상 관측소 코드 매핑 생성\n",
        "dms_station_mapping = {}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    dms_code = row['DMS CODE']\n",
        "    dms_name = row['DMS 관측소명']\n",
        "    first_priority = row['1순위 관측소 코드']\n",
        "    second_priority = row['2순위 관측소 코드']\n",
        "\n",
        "    dms_station_mapping[dms_code] = {\n",
        "        '기상 1순위': first_priority,\n",
        "        '기상 2순위': second_priority,\n",
        "        'dms_name': dms_name\n",
        "    }\n",
        "\n",
        "# 원하는 DMS CODE 목록\n",
        "desired_dms_codes = df['DMS CODE'].tolist()  # 모든 DMS CODE를 목록에 추가\n",
        "\n",
        "# API 기본 URL\n",
        "domain = \"https://apihub.kma.go.kr/api/typ01/url/awsh.php?\"\n",
        "var = 'var='\n",
        "option = \"authKey=\"  # 인증키\n",
        "\n",
        "def fetch_data(start_date, end_date):\n",
        "    \"\"\"데이터를 한 번에 가져오는 함수.\"\"\"\n",
        "    data_for_all = []\n",
        "    current_time = start_date\n",
        "\n",
        "    while current_time <= end_date:\n",
        "        # 19시부터 5시까지만 데이터 접근\n",
        "        if current_time.hour >= 19 or current_time.hour <= 5:\n",
        "            tm = current_time.strftime(\"%Y%m%d%H%M\")\n",
        "            url = f\"{domain}{var}&tm={tm}&stn=0&{option}\"\n",
        "\n",
        "            print(f\"Fetching data for {current_time.strftime('%Y-%m-%d %H:%M')} with URL: {url}\")\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                if response.status_code == 200:\n",
        "                    text_data = response.text.strip()\n",
        "                    if text_data:\n",
        "                        lines = text_data.splitlines()\n",
        "                        for line in lines:\n",
        "                            if line.strip() and not line.startswith('#'):\n",
        "                                fields = line.split()\n",
        "                                station_id = int(fields[1])\n",
        "\n",
        "                                # 원하는 기상 관측소 코드만 필터링\n",
        "                                for dms_code in desired_dms_codes:\n",
        "                                    first_priority = dms_station_mapping[dms_code]['기상 1순위']\n",
        "                                    second_priority = dms_station_mapping[dms_code]['기상 2순위']\n",
        "                                    dms_name = dms_station_mapping[dms_code]['dms_name']\n",
        "                                    if station_id == first_priority or station_id == second_priority:\n",
        "                                        temp = np.nan if float(fields[2]) == -99 else float(fields[2])\n",
        "                                        wdspeed = np.nan if float(fields[4]) == -99 else float(fields[4])\n",
        "                                        rain_1hr = np.nan if float(fields[6]) == -99 else float(fields[6])\n",
        "                                        humidity = np.nan if float(fields[7]) == -99 else float(fields[7])\n",
        "\n",
        "                                        # 'remark' 열을 1순위 또는 2순위로 설정\n",
        "                                        remark = '1순위' if station_id == first_priority else '2순위'\n",
        "\n",
        "                                        data_for_all.append({\n",
        "                                            'time': tm,\n",
        "                                            'DMS_CODE': dms_code,  # DMS CODE 추가,\n",
        "                                            '측정소명': dms_name,\n",
        "                                            'stdid': station_id,   # 'stdid' 열 추가\n",
        "                                            'temp': temp,\n",
        "                                            'wdspeed': wdspeed,\n",
        "                                            'rain_1hr': rain_1hr,\n",
        "                                            'humidity': humidity,\n",
        "                                            'remark': remark  # remark 열 추가\n",
        "                                        })\n",
        "                else:\n",
        "                    print(f\"Error {response.status_code} occurred. Waiting 1 hour before retrying...\")\n",
        "                    time.sleep(300)  # 30분 대기\n",
        "                    continue  # 현재 시간에 대해 다시 시도\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}. Retrying after 1 hour...\")\n",
        "                time.sleep(300)  # 30분 대기\n",
        "                continue  # 현재 시간에 대해 다시 시도\n",
        "\n",
        "            time.sleep(1)  # API 호출 간의 딜레이\n",
        "\n",
        "        current_time += timedelta(hours=1)\n",
        "\n",
        "    # 리스트를 DataFrame으로 변환\n",
        "    return pd.DataFrame(data_for_all)\n",
        "\n",
        "def adjust_date_for_nighttime(data):\n",
        "    \"\"\"19:00~05:00 데이터를 다음 날로 조정.\"\"\"\n",
        "    data['date'] = pd.to_datetime(data['time'], format='%Y%m%d%H%M')  # 'time'을 datetime 형식으로 변환\n",
        "    data['hour'] = data['date'].dt.hour  # 'date'가 datetime 형식이므로 .dt 사용 가능\n",
        "    data['측정일'] = data['date'].dt.date  # 'adjusted_date'를 날짜만으로 추출\n",
        "    data.loc[data['hour'] >= 19, '측정일'] += timedelta(days=1)  # 19시 이후는 다음 날로 변경\n",
        "\n",
        "    # adjusted_date를 datetime 형식으로 변환\n",
        "    data['측정일'] = pd.to_datetime(data['측정일'])\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def aggregate_daily_data(data):\n",
        "    \"\"\"1순위와 2순위 데이터를 일별로 집계.\"\"\"\n",
        "    aggregated = (\n",
        "        data.groupby(['측정일', 'DMS_CODE', '측정소명', 'remark'])\n",
        "        .agg(\n",
        "            TMP=('temp', 'mean'),\n",
        "            TMAX=('temp', 'max'),\n",
        "            TMAX=('temp', 'min'),\n",
        "            PCP=('rain_1hr', 'sum'),\n",
        "            HUM=('humidity', 'mean'),\n",
        "            WS=('wdspeed', 'mean')\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "    return aggregated\n",
        "\n",
        "\n",
        "def process_and_fill_gaps(aggregated_data):\n",
        "    \"\"\"1순위 데이터를 우선 사용하고, 결측치를 2순위, 3순위, 4순위로 보완.\"\"\"\n",
        "    result = []\n",
        "\n",
        "    for dms_code in desired_dms_codes:\n",
        "        # 1순위 및 2순위 데이터 선택\n",
        "        first_priority = aggregated_data[\n",
        "            (aggregated_data['DMS_CODE'] == dms_code) & (aggregated_data['remark'] == '1순위')\n",
        "        ].set_index('측정일')\n",
        "\n",
        "        second_priority = aggregated_data[\n",
        "            (aggregated_data['DMS_CODE'] == dms_code) & (aggregated_data['remark'] == '2순위')\n",
        "        ].set_index('측정일')\n",
        "\n",
        "        # 1순위 데이터를 기준으로 초기화\n",
        "        merged = first_priority.copy()\n",
        "\n",
        "        # 결측치가 있는 항목을 2순위 데이터로 보완\n",
        "        for col in ['TMP', 'TMAX', 'TMIN', 'PCP', 'HUM', 'WS']:\n",
        "            if col in merged.columns:\n",
        "                # 보완 전 결측치 위치 추적\n",
        "                missing_before_fill = merged[col].isna()\n",
        "\n",
        "                before_fill = missing_before_fill.sum()\n",
        "                merged[col] = merged[col].combine_first(second_priority[col])\n",
        "\n",
        "                # 보완 후 채워진 값의 위치\n",
        "                filled_indices = missing_before_fill & merged[col].notna()\n",
        "\n",
        "                after_fill = merged[col].isna().sum()\n",
        "                print(f\"{dms_code}: {col} - 2순위 보완: 결측치 {before_fill}개 중 {before_fill - after_fill}개 보완 완료.\")\n",
        "\n",
        "                # 'remark' 열에 2순위 보완으로 덮어쓰기 (보완된 값들에 한정)\n",
        "                merged.loc[filled_indices, 'remark'] = f'2순위 보완-{col}'\n",
        "\n",
        "                # 2순위로도 결측치가 남아있다면, 같은 날짜 다른 연도의 데이터를 사용하여 보완 (3순위)\n",
        "                missing_dates = merged[merged[col].isna()].index\n",
        "                for date in missing_dates:\n",
        "                    # 3순위 보완이 아직 처리되지 않은 날짜에 대해서만 진행\n",
        "                    if '3순위 보완' not in str(merged.at[date, 'remark']):\n",
        "                        # 다른 연도의 같은 날짜 값들의 평균을 계산 (1순위 및 2순위와 무관)\n",
        "                        same_day_data = merged[\n",
        "                            (merged.index.month == date.month) &\n",
        "                            (merged.index.day == date.day) &\n",
        "                            (merged['DMS_CODE'] == dms_code)  # dms_code 기준으로 필터링\n",
        "                        ]\n",
        "\n",
        "                        # 평균값 계산\n",
        "                        avg_value = same_day_data[col].dropna().mean()  # NaN 제외 후 평균 계산\n",
        "\n",
        "                        # avg_value가 NaN인 경우 3순위 보완을 진행하지 않음\n",
        "                        if not np.isnan(avg_value):\n",
        "                            # 결측치가 있을 경우에만 채우기\n",
        "                            if pd.isna(merged.at[date, col]):\n",
        "                                merged.at[date, col] = avg_value\n",
        "                                merged.at[date, 'remark'] = f'3순위 보완-{col}'  # 3순위 보완으로 표시\n",
        "                                print(f\"{dms_code}: {col} - 3순위 보완: 날짜 {date}에서 값 {avg_value}로 보완 완료.\")\n",
        "                        else:\n",
        "                            # 3순위 보완 실패시 바로 4순위로 넘어감\n",
        "                            print(f\"{dms_code}: {col} - 3순위 보완 실패: 날짜 {date}에서 3순위 보완을 진행할 수 없음. 4순위로 진행.\")\n",
        "\n",
        "                            # 4순위 보완 (선형 보간법) 진행\n",
        "                            missing_dates_4th = merged[merged[col].isna()].index\n",
        "                            if not missing_dates_4th.empty:\n",
        "                                before_fill_4th = merged[col].isna().sum()\n",
        "                                merged[col] = merged[col].interpolate(method='linear')\n",
        "                                after_fill_4th = merged[col].isna().sum()\n",
        "                                print(f\"{dms_code}: {col} - 4순위 보완 (선형 보간법): 결측치 {before_fill_4th}개 중 {before_fill_4th - after_fill_4th}개 보완 완료.\")\n",
        "\n",
        "                                # 'remark' 열에 '4순위'를 추가\n",
        "                                merged.loc[merged[col].notna(), 'remark'] = merged.loc[merged[col].notna(), 'remark'].apply(\n",
        "                                    lambda x: f'{x}, 4순위 보완-{col}' if x else f'4순위 보완-{col}')\n",
        "\n",
        "\n",
        "        # 결과 반환 시 remark를 그대로 사용\n",
        "        result.append(merged.reset_index())\n",
        "\n",
        "    return pd.concat(result, ignore_index=True)\n",
        "\n",
        "def calculate_monthly_and_yearly_averages(data):\n",
        "    \"\"\"월평균과 연평균 온도를 계산하는 함수.\"\"\"\n",
        "    # 월평균 온도 계산\n",
        "    data['month'] = data['측정일'].dt.to_period('M')  # 'YYYY-MM' 형식으로 월 추출\n",
        "    monthly_avg = data.groupby(['month', 'DMS_CODE'])['TMP'].mean().reset_index()\n",
        "    monthly_avg.rename(columns={'TMP': 'Temp_1_monthly_mean'}, inplace=True)\n",
        "\n",
        "    # 연평균 온도 계산\n",
        "    data['year'] = data['측정일'].dt.year  # 연도 추출\n",
        "    yearly_avg = data.groupby(['year', 'DMS_CODE'])['TMP'].mean().reset_index()\n",
        "    yearly_avg.rename(columns={'TMP': 'Temp_1_yearly_mean'}, inplace=True)\n",
        "\n",
        "    # 결과 병합\n",
        "    data = pd.merge(data, monthly_avg, on=['month', 'DMS_CODE'], how='left')\n",
        "    data = pd.merge(data, yearly_avg, on=['year', 'DMS_CODE'], how='left')\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def fetch_and_process_all_years():\n",
        "    all_raw_data = []  # 모든 년도 데이터를 저장할 리스트\n",
        "\n",
        "    # 2015년부터 2022년까지 모든 데이터를 가져오기\n",
        "    years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "    for year in years:\n",
        "        start_date = datetime(year, 3, 31, 19, 0)\n",
        "        end_date = datetime(year, 10, 31, 5, 0)\n",
        "\n",
        "        raw_data = fetch_data(start_date, end_date)\n",
        "        all_raw_data.append(raw_data)  # 각 년도의 데이터를 리스트에 추가\n",
        "\n",
        "    # 모든 년도의 데이터를 하나로 합친 후\n",
        "    combined_data = pd.concat(all_raw_data, ignore_index=True)\n",
        "\n",
        "    # 날짜 처리: 각 년도의 데이터가 합쳐졌으므로 날짜 조정\n",
        "    adjusted_data = adjust_date_for_nighttime(combined_data)\n",
        "\n",
        "    # 일별 집계\n",
        "    aggregated_data = aggregate_daily_data(adjusted_data)\n",
        "\n",
        "    # 결측치 처리: 1순위, 2순위, 3순위, 4순위 순으로 처리\n",
        "    filled_data = process_and_fill_gaps(aggregated_data)\n",
        "\n",
        "    # 최종 데이터 처리\n",
        "    final_data = calculate_monthly_and_yearly_averages(filled_data)\n",
        "\n",
        "    return final_data\n",
        "\n",
        "\n",
        "# 모든 데이터를 한 번에 처리\n",
        "if __name__ == \"__main__\":\n",
        "    final_processed_data = fetch_and_process_all_years()\n",
        "\n",
        "    # 'month, year' 컬럼을 제외하고 저장\n",
        "    final_processed_data.drop(columns=['month', 'year'], inplace=True, errors='ignore')\n",
        "\n",
        "    # 열 이름 설정 및 순서 재정렬\n",
        "    colname = ['측정일', 'DMS_CODE', '측정소명', '비고', 'TMP', 'TMAX', 'TMIN', 'PCP', 'HUM', 'WS', 'Temp_1_monthly_mean', 'Temp_1_yearly_mean']\n",
        "    final_processed_data.columns = colname\n",
        "    final_processed_data = final_processed_data[['측정일', 'DMS_CODE','측정소명', 'TMP', 'TMAX', 'TMIN', 'PCP', 'HUM', 'WS', 'Temp_1_monthly_mean', 'Temp_1_yearly_mean', '비고']]\n",
        "\n",
        "\n",
        "    # 결과 저장\n",
        "    final_processed_data.to_excel(\"2015_2022_mosquito.xlsx\", index=False)\n",
        "    print(\"All data processing complete. Saved to '2015_2022_mosquito.xlsx'.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}