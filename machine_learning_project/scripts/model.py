import numpy as np
import pandas as pd
import os
import joblib
import sys
import random
import multiprocessing
import re
import config
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, r2_score
from hyperopt import fmin, tpe, Trials, STATUS_OK
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import hyperopt.hp as hp 


def get_param_space(model_name):
    """config.pyì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì ¸ì™€ì„œ hyperopt í˜•íƒœë¡œ ë³€í™˜"""
    param_ranges = config.HYPERPARAMS[model_name]
    
    param_space = {}
    for key, value in param_ranges.items():
        if len(value) == 3:  # quniform
            param_space[key] = hp.quniform(key, *value)
        elif len(value) == 2:  # loguniform (learning_rate ê°™ì€ ê²½ìš°)
            param_space[key] = hp.loguniform(key, np.log(max(value[0], 1e-3)), np.log(value[1]))
    
    return param_space

def train_model(model_cls, param_space, n_iter_count, save_path, region, model_name, 
                X_train_scaled, X_test_scaled, y_train, y_test, train_data_sorted, 
                test_data_sorted, landscape):
    
    # ğŸ”¹ ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ëœë¤ ì‹œë“œ ê³ ì • (ì¬í˜„ì„± ë³´ì¥)
    np.random.seed(42)
    random.seed(42)
    rstate = np.random.default_rng(42)

    def objective(params):
        for key in ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'num_leaves', 'min_child_samples']:
            if key in params:
                params[key] = int(params[key])

        model = model_cls(**params, random_state=42)  # âœ… ëª¨ë“  CPU ì‚¬ìš©

        # âœ… TimeSeriesSplit ì ìš© (3ê°œ ë¶„í•  ì‚¬ìš©)
        tscv = TimeSeriesSplit(n_splits=3)
        rmse_scores = []

        for train_idx, val_idx in tscv.split(X_train_scaled):
            X_train_fold, X_val_fold = X_train_scaled.iloc[train_idx], X_train_scaled.iloc[val_idx]
            y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]

            model.fit(X_train_fold, y_train_fold)
            y_pred = model.predict(X_val_fold)
            rmse_scores.append(np.sqrt(mean_squared_error(y_val_fold, y_pred)))

        avg_rmse = np.mean(rmse_scores)  # âœ… TimeSeriesSplit ê¸°ë°˜ RMSE ê³„ì‚°
        return {'loss': avg_rmse, 'status': STATUS_OK}

    log_filename = f"{model_name}_training.log"
    log_filepath = os.path.join(save_path, log_filename)

    original_stdout = sys.stdout  
    try:
        os.makedirs(save_path, exist_ok=True)  
        sys.stdout = open(log_filepath, 'w', encoding="utf-8")
        sys.stderr = sys.stdout  

        trials = Trials()
        best_params = fmin(fn=objective, space=param_space, algo=tpe.suggest, 
                           max_evals=n_iter_count, trials=trials, rstate=rstate)  # ğŸ”¥ hyperopt ì‹œë“œ ê³ ì •

        # ğŸ”¥ ìµœì  íŒŒë¼ë¯¸í„° ë³€í™˜ ì¶”ê°€
        for key in ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'num_leaves', 'min_child_samples']:
            if key in best_params:
                best_params[key] = int(best_params[key])

        best_model = model_cls(**best_params, random_state=42)  
        if model_name in ["xgb", "lgbm"]:
            best_model.fit(
                X_train_scaled, y_train,
                eval_set=[(X_test_scaled, y_test)],
                early_stopping_rounds=50,  # âœ… ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨
                verbose=100
            )
        else:
            best_model.fit(X_train_scaled, y_train)  # âŒ eval_set ì—†ì´ í•™ìŠµ


        joblib.dump(best_model, os.path.join(save_path, f"{model_name}.pkl"))

        y_pred_train = best_model.predict(X_train_scaled)
        y_pred_test = best_model.predict(X_test_scaled)

        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))

        print(f"ğŸ“Š Best Hyperparameters for {model_name}: {best_params}")
        print(f"âœ… {model_name} RMSE (Train): {train_rmse:.4f}, RMSE (Test): {test_rmse:.4f}")
        print(f"âœ… {model_name} RÂ² (Train): {train_r2:.4f}, RÂ² (Test): {test_r2:.4f}")

    finally:
        sys.stdout.flush()  # âœ… ë¡œê·¸ ìœ ì‹¤ ë°©ì§€
        sys.stdout.close()
        sys.stdout = original_stdout  

    return best_model


def run_models(n_iter_count, save_path, region, X_train_scaled, X_test_scaled, y_train, y_test, train_data_sorted, test_data_sorted, landscape):
    models = {
        'lgbm': (LGBMRegressor, get_param_space('lgbm')),
        'rf': (RandomForestRegressor, get_param_space('rf')),
        'gb': (GradientBoostingRegressor, get_param_space('gb')),
        'xgb': (XGBRegressor, get_param_space('xgb'))
    }
    
    models_to_run = {name: (cls, space) for name, (cls, space) in models.items() if name in config.MODELS_TO_RUN}
    max_cores = multiprocessing.cpu_count()
    optimal_cores = max(2, max_cores - 2)  # âœ… ìµœì†Œ 2ê°œ ì½”ì–´ ìœ ì§€

    pool = multiprocessing.Pool(processes=optimal_cores)
    results = {}
    async_results = []

    for name, (cls, space) in models_to_run.items():
        async_result = pool.apply_async(
            train_model, 
            args=(cls, space, n_iter_count, save_path, region, name, X_train_scaled, X_test_scaled, y_train, y_test, train_data_sorted, test_data_sorted, landscape)
        )
        async_results.append((name, async_result))

    pool.close()
    pool.join()

    for name, async_result in async_results:
        results[name] = async_result.get()

    return results


def get_unique_filename(directory, base_name, landscape, extension="png"):
    """
    ì£¼ì–´ì§„ ë””ë ‰í† ë¦¬ì—ì„œ base_nameê³¼ landscapeë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ì„ ì°¾ì•„
    ê°€ì¥ í° ìˆ«ì ë‹¤ìŒ ìˆ«ìë¡œ íŒŒì¼ëª… ìƒì„±
    """
    if not os.path.exists(directory):  # ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ ìƒì„±
        os.makedirs(directory, exist_ok=True)

    filename_prefix = f"{base_name}_landscape{landscape}_"
    existing_files = [f for f in os.listdir(directory) if f.startswith(filename_prefix) and f.endswith(f".{extension}")]

    # ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì•ˆì •ì„± ê°œì„ )
    numbers = []
    pattern = re.compile(rf"{re.escape(filename_prefix)}(\d+)\.{extension}")
    
    for f in existing_files:
        match = pattern.match(f)
        if match:
            numbers.append(int(match.group(1)))

    next_number = max(numbers) + 1 if numbers else 1  # ìˆ«ì ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ 1

    return os.path.join(directory, f"{filename_prefix}{next_number}.{extension}")


def load_and_predict(save_path, model_name, X_test_scaled, train_data_sorted, test_data_sorted, best_params, train_rmse, test_rmse, train_r2, test_r2, landscape, n_iter_count):
    model_full_names = {
        "lgbm": "LightGBM",
        "xgb": "Extreme Gradient Boosting",
        "rf": "Random Forest",
        "gb": "Gradient Boosting"
    }
    model_colors = {
        "lgbm": "green",
        "xgb": "red",
        "rf": "blue",
        "gb": "orange"
    }
    
    full_model_name = model_full_names.get(model_name, model_name)
    model_color = model_colors.get(model_name, "red")
    model = joblib.load(os.path.join(save_path, f"{model_name}.pkl"))
    y_test_pred = model.predict(X_test_scaled)
    
    plt.figure(figsize=(12, 8))
    plt.plot(test_data_sorted['DATE'], test_data_sorted['mosquito'], label='Actual', color='black')
    plt.plot(test_data_sorted['DATE'], y_test_pred, label='Prediction', color=model_color)
    plt.legend()
    plt.xlabel("Date")
    plt.ylabel("Mosquito Count")
    plt.title(f"{full_model_name} Prediction", fontsize=25)
    plt.grid()
    
    textstr = f"RMSE (Train): {train_rmse:.4f}  RMSE (Test): {test_rmse:.4f}\nRÂ² (Train): {train_r2:.4f}  RÂ² (Test): {test_r2:.4f}\nLandscape: {landscape}  n_iter_count: {n_iter_count}"
    plt.figtext(0.5, 0.08, textstr, fontsize=14, ha='center', va='center')
    plt.subplots_adjust(bottom=0.25)
    
    os.makedirs(save_path, exist_ok=True)
    unique_filename = get_unique_filename(save_path, model_name, landscape, "png")  # âœ… íŒŒì¼ëª… ìë™ ì¦ê°€
    plt.savefig(unique_filename)
    print(f"âœ… ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {unique_filename}")


## tasklist | findstr python

## taskkill /F /IM python3.11.exe
