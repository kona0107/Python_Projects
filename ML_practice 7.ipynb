{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Manual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습(7)\n",
    "하이퍼파라미터 튜닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Grid search\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 데이터 로드\n",
    "housing = fetch_california_housing()\n",
    "target = housing.target\n",
    "data = housing.data\n",
    "df_X = pd.DataFrame(data, columns=housing.feature_names)\n",
    "df_y = pd.DataFrame(target, columns=[\"Target\"])\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링\n",
    "S_scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(S_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scale = pd.DataFrame(S_scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# RandomForest 모델 정의 및 하이퍼파라미터 그리드 설정\n",
    "RF = RandomForestRegressor()\n",
    "params_Grid = {\n",
    "    'n_estimators': np.arange(20, 40),\n",
    "    'max_depth': np.arange(2, 4),\n",
    "    'min_samples_split': np.arange(2, 4),\n",
    "    'min_samples_leaf': np.arange(2, 4)\n",
    "}\n",
    "\n",
    "# GridSearchCV 실행\n",
    "Grid_serach = GridSearchCV(\n",
    "    RF,\n",
    "    param_grid=params_Grid,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "Grid_serach.fit(X_train_scale, y_train)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"최적의 하이퍼파라미터는 : {Grid_serach.best_params_}\\n 최적의 점수는 : {Grid_serach.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Random search\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 데이터 로드\n",
    "housing = fetch_california_housing()\n",
    "target = housing.target\n",
    "data = housing.data\n",
    "df_X = pd.DataFrame(data, columns=housing.feature_names)\n",
    "df_y = pd.DataFrame(target, columns=[\"Target\"])\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링\n",
    "S_scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(S_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scale = pd.DataFrame(S_scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# RandomForest 모델 정의 및 하이퍼파라미터 설정\n",
    "RF = RandomForestRegressor()\n",
    "params_random = {\n",
    "    'n_estimators': np.arange(10, 200),\n",
    "    'max_depth': np.arange(2, 6),\n",
    "    'min_samples_split': np.arange(2, 6),\n",
    "    'min_samples_leaf': np.arange(2, 6)\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV 실행\n",
    "Random_serach = RandomizedSearchCV(\n",
    "    RF,\n",
    "    param_distributions=params_random,\n",
    "    cv=5,\n",
    "    n_iter=100,\n",
    "    verbose=1,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "Random_serach.fit(X_train_scale, y_train)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"최적의 하이퍼파라미터는 : {Random_serach.best_params_}\\n 최적의 점수는 : {Random_serach.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Bayesian Optimization(optuna)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "# 데이터 로드\n",
    "housing = fetch_california_housing()\n",
    "target = housing.target\n",
    "data = housing.data\n",
    "df_X = pd.DataFrame(data, columns=housing.feature_names)\n",
    "df_y = pd.DataFrame(target, columns=[\"Target\"])\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링\n",
    "S_scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(S_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scale = pd.DataFrame(S_scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Objective Function\n",
    "def objective(trial: Trial):\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    n_estimators = trial.suggest_int('n_estimators', 30, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 8)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 8)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 8)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # KFold 교차 검증 설정 (5-fold)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    # 교차 검증\n",
    "    for train_index, valid_index in kf.split(X_train_scale):\n",
    "        X_fold_train, X_fold_valid = X_train_scale.iloc[train_index], X_train_scale.iloc[valid_index]\n",
    "        y_fold_train, y_fold_valid = y_train[train_index], y_train[valid_index]\n",
    "\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        fold_predictions = model.predict(X_fold_valid)\n",
    "        score = r2_score(y_fold_valid, fold_predictions)\n",
    "        scores.append(score)\n",
    "\n",
    "    # 교차 검증 평균 R² 반환\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Hyperband 프루너 설정\n",
    "pruner = HyperbandPruner(\n",
    "    min_resource=1,\n",
    "    max_resource=100,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "# Optuna 스터디 생성 (랜덤 시드 설정)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best score:\", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
