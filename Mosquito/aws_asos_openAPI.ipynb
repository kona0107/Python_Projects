{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'날짜'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '날짜'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 138\u001b[0m\n\u001b[0;32m    135\u001b[0m daily_aws_data \u001b[38;5;241m=\u001b[39m aggregate_daily_data(filtered_aws_data)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# 결측치 보완\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_missing_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_aws_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masos_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n\u001b[0;32m    141\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(SAVE_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmapel2_weather_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[50], line 112\u001b[0m, in \u001b[0;36mhandle_missing_data\u001b[1;34m(df, backup_station_data)\u001b[0m\n\u001b[0;32m    109\u001b[0m missing_dates \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m날짜\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m missing_dates:\n\u001b[1;32m--> 112\u001b[0m     backup_data \u001b[38;5;241m=\u001b[39m backup_station_data[\u001b[43mbackup_station_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m날짜\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m date]\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backup_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기온_평균\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기온_최대\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기온_최소\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m강수량_합\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m풍속_평균\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m습도_평균\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '날짜'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import io\n",
    "\n",
    "# API 설정\n",
    "API_KEY = 's5DFRYyOQqKQxUWMjlKi9g'\n",
    "AWS_URL = 'https://apihub.kma.go.kr/api/typ01/url/awsh.php'\n",
    "ASOS_URL = 'https://apihub.kma.go.kr/api/typ01/url/kma_sfctm2.php'\n",
    "SAVE_PATH = 'F:/박정현/ML/Mosquito/'\n",
    "\n",
    "# DMS 시간 필터링: 전일 19시 ~ 당일 5시\n",
    "def filter_time_range(df, start_time='19:00', end_time='05:00'):\n",
    "    df.rename(columns={df.columns[0]: 'YYMMDDHHMI'}, inplace=True)\n",
    "    df['시간'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M')\n",
    "    df['시간'] = df['시간'].dt.strftime('%H:%M')  # 시간만 문자열로 추출\n",
    "\n",
    "    return df[(df['시간'] >= start_time) | (df['시간'] <= end_time)]\n",
    "\n",
    "# AWS 데이터 다운로드 함수\n",
    "def download_aws_data(start_date, end_date):\n",
    "    data_frames = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        params = {\n",
    "            'authKey': API_KEY,\n",
    "            'tm': current_date.strftime('%Y%m%d%H%M'),  # 시간 포함\n",
    "            'var': '0',  # 모든 필요한 데이터 요청\n",
    "            'stn': 0  # 전체 관측소 요청\n",
    "        }\n",
    "\n",
    "        response = requests.get(AWS_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            raw_text = response.text\n",
    "            raw_data = \"\\n\".join(line for line in raw_text.splitlines() if not line.startswith(\"#\"))\n",
    "            df = pd.read_csv(io.StringIO(raw_data), sep='\\s+')\n",
    "            # 열 이름 확인 후 재설정\n",
    "            if len(df.columns) == 10:\n",
    "                df.columns = ['YYMMDDHHMI', 'STN', 'TA', 'WD', 'WS', 'RN_DAY', 'RN_HR1', 'HM', 'PA', 'PS']\n",
    "            data_frames.append(df)\n",
    "        else:\n",
    "            print(f\"Failed to fetch AWS data for {current_date}: {response.status_code}\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    if data_frames:\n",
    "        return pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"No AWS data available for the given date range\")\n",
    "\n",
    "# ASOS 데이터 다운로드 함수\n",
    "def download_asos_data(start_date, end_date):\n",
    "    data_frames = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        params = {\n",
    "            'authKey': API_KEY,\n",
    "            'tm': current_date.strftime('%Y%m%d%H%M'),  # 시간 포함\n",
    "            'stn': 0  # 전체 관측소 요청\n",
    "        }\n",
    "\n",
    "        response = requests.get(ASOS_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            raw_text = response.text\n",
    "            raw_data = \"\\n\".join(line for line in raw_text.splitlines() if not line.startswith(\"#\"))\n",
    "            df = pd.read_csv(io.StringIO(raw_data), sep='\\s+')\n",
    "            # 열 이름 확인 후 재설정\n",
    "            if len(df.columns) == 10:\n",
    "                df.columns = ['YYMMDDHHMI', 'STN', 'TA', 'WD', 'WS', 'RN_DAY', 'RN_HR1', 'HM', 'PA', 'PS']\n",
    "            data_frames.append(df)\n",
    "        else:\n",
    "            print(f\"Failed to fetch ASOS data for {current_date}: {response.status_code}\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    if data_frames:\n",
    "        return pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"No ASOS data available for the given date range\")\n",
    "\n",
    "# 일 단위 변환 함수\n",
    "def aggregate_daily_data(df):\n",
    "    df['날짜'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M')\n",
    "    daily_data = df.groupby(df['날짜'].dt.date).agg({\n",
    "        'TA': ['mean', 'max', 'min'],\n",
    "        'RN_DAY': 'sum',\n",
    "        'WS': 'mean',\n",
    "        'HM': 'mean'\n",
    "    }).reset_index()\n",
    "    daily_data.columns = ['날짜', '기온_평균', '기온_최대', '기온_최소', '강수량_합', '풍속_평균', '습도_평균']\n",
    "    return daily_data\n",
    "\n",
    "# 결측치 처리 함수\n",
    "def handle_missing_data(df, backup_station_data):\n",
    "    # '날짜' 열이 있는지 확인\n",
    "    if '날짜' not in df.columns:\n",
    "        raise KeyError(\"'날짜' 열이 데이터프레임에 없습니다. 데이터 전처리 단계를 확인하세요.\")\n",
    "    \n",
    "    # '날짜' 열이 datetime 형식인지 확인 및 변환\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['날짜']):\n",
    "        df['날짜'] = pd.to_datetime(df['날짜'], errors='coerce')\n",
    "\n",
    "    # -99.0을 결측치로 간주\n",
    "    df[['기온_평균', '기온_최대', '기온_최소', '강수량_합', '풍속_평균', '습도_평균']] = df[['기온_평균', '기온_최대', '기온_최소', '강수량_합', '풍속_평균', '습도_평균']].replace(-99.0, pd.NA)\n",
    "\n",
    "    missing_dates = df[df.isnull().any(axis=1)]['날짜']\n",
    "\n",
    "    for date in missing_dates:\n",
    "        backup_data = backup_station_data[backup_station_data['날짜'] == date]\n",
    "        if not backup_data.empty:\n",
    "            for col in ['기온_평균', '기온_최대', '기온_최소', '강수량_합', '풍속_평균', '습도_평균']:\n",
    "                df.loc[df['날짜'] == date, col] = backup_data[col].values[0]\n",
    "        else:\n",
    "            # 해당 날짜의 다른 연도 평균값으로 대체\n",
    "            other_years_data = df[(df['날짜'].dt.month == date.month) & (df['날짜'].dt.day == date.day)]\n",
    "            if not other_years_data.empty:\n",
    "                for col in ['기온_평균', '기온_최대', '기온_최소', '강수량_합', '풍속_평균', '습도_평균']:\n",
    "                    df.loc[df['날짜'] == date, col] = other_years_data[col].mean()\n",
    "\n",
    "    return df.interpolate()\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = datetime(2015, 3, 31)\n",
    "    end_date = datetime(2015, 4, 5)\n",
    "\n",
    "    try:\n",
    "        aws_data = download_aws_data(start_date, end_date)\n",
    "        asos_data = download_asos_data(start_date, end_date)\n",
    "\n",
    "        filtered_aws_data = filter_time_range(aws_data)\n",
    "        daily_aws_data = aggregate_daily_data(filtered_aws_data)\n",
    "\n",
    "        # 결측치 보완\n",
    "        processed_data = handle_missing_data(daily_aws_data, asos_data)\n",
    "\n",
    "        # 결과 저장\n",
    "        output_file = os.path.join(SAVE_PATH, \"smapel2_weather_data.csv\")\n",
    "        processed_data.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"File saved to: {os.path.abspath(output_file)}\")\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily AWS Data Columns: Index(['지점', '날짜', '평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)',\n",
      "       '평균 상대습도(%)'],\n",
      "      dtype='object')\n",
      "   지점          날짜  평균기온(℃)  최고기온(℃)  최저기온(℃)  일강수량(mm)  평균풍속(m/s)  평균 상대습도(%)\n",
      "0   2  2015-03-31      7.5      7.5      7.5       0.0        1.1        56.6\n",
      "1   2  2015-04-01     11.5     11.5     11.5       0.5        0.2        94.5\n",
      "2   2  2015-04-02      3.8      3.8      3.8       0.0        0.9        83.4\n",
      "3   3  2015-03-31     16.8     16.8     16.8       0.0        2.9         NaN\n",
      "4   3  2015-04-01     17.0     17.0     17.0       0.0        0.4         NaN\n",
      "File saved to: F:\\박정현\\ML\\Mosquito\\sample3_weather_data.csv\n",
      "Data saved to F:/박정현/ML/Mosquito/sample3_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import io\n",
    "\n",
    "# API 설정\n",
    "API_KEY = 's5DFRYyOQqKQxUWMjlKi9g'\n",
    "AWS_URL = 'https://apihub.kma.go.kr/api/typ01/url/awsh.php'\n",
    "ASOS_URL = 'https://apihub.kma.go.kr/api/typ01/url/kma_sfctm2.php'\n",
    "SAVE_PATH = 'F:/박정현/ML/Mosquito/'\n",
    "\n",
    "# DMS 시간 필터링: 전일 19시 ~ 당일 5시\n",
    "def filter_time_range(df, start_time='19:00', end_time='05:00'):\n",
    "    df.rename(columns={df.columns[0]: 'YYMMDDHHMI'}, inplace=True)\n",
    "    df['시간'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M')\n",
    "    df['시간'] = df['시간'].dt.strftime('%H:%M')  # 시간만 문자열로 추출\n",
    "\n",
    "    return df[(df['시간'] >= start_time) | (df['시간'] <= end_time)]\n",
    "\n",
    "# AWS 데이터 다운로드 함수\n",
    "def download_aws_data(start_date, end_date):\n",
    "    data_frames = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        params = {\n",
    "            'authKey': API_KEY,\n",
    "            'tm': current_date.strftime('%Y%m%d%H%M'),  # 시간 포함\n",
    "            'var': '0',  # 모든 필요한 데이터 요청\n",
    "            'stn': '0'  # 특정 관측소 요청\n",
    "        }\n",
    "\n",
    "        response = requests.get(AWS_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            raw_text = response.text\n",
    "            raw_data = response.text\n",
    "            df = pd.read_csv(io.StringIO(raw_data), sep='\\s+', comment='#', skip_blank_lines=True)\n",
    "            # 열 이름 확인 후 재설정\n",
    "            if len(df.columns) == 10:\n",
    "                df.columns = ['YYMMDDHHMI', 'STN', 'TA', 'WD', 'WS', 'RN_DAY', 'RN_HR1', 'HM', 'PA', 'PS']\n",
    "            data_frames.append(df)\n",
    "        else:\n",
    "            print(f\"Failed to fetch AWS data for {current_date}: {response.status_code}\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    if data_frames:\n",
    "        return pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"No AWS data available for the given date range\")\n",
    "\n",
    "# ASOS 데이터 다운로드 함수\n",
    "def download_asos_data(start_date, end_date):\n",
    "    data_frames = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        params = {\n",
    "            'authKey': API_KEY,\n",
    "            'tm': current_date.strftime('%Y%m%d%H%M'),  # 시간 포함\n",
    "            'stn': 108  # 특정 관측소 요청\n",
    "        }\n",
    "\n",
    "        response = requests.get(ASOS_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            raw_text = response.text\n",
    "            raw_data = response.text\n",
    "            df = pd.read_csv(io.StringIO(raw_data), sep='\\s+', header=None, comment='#', skip_blank_lines=True)\n",
    "            # 필요한 열만 선택\n",
    "            if df.shape[1] >= 10:  # 최소 10개 이상의 열이 있을 경우\n",
    "                df = df.iloc[:, [0, 1, 11, 3, 15, 13]]  # 필요한 열 선택: YYMMDDHHMI, STN, TA, WS, RN, HM\n",
    "                df.columns = ['YYMMDDHHMI', 'STN', 'TA', 'WS', 'RN', 'HM']\n",
    "                # '날짜' 열 추가\n",
    "                df['날짜'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M').dt.date\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected number of columns in ASOS data for {current_date}\")\n",
    "            data_frames.append(df)\n",
    "        else:\n",
    "            print(f\"Failed to fetch ASOS data for {current_date}: {response.status_code}\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    if data_frames:\n",
    "        return pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"No ASOS data available for the given date range\")\n",
    "\n",
    "# 일 단위 변환 함수\n",
    "def aggregate_daily_data(df):\n",
    "    df['날짜'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M')\n",
    "    daily_data = df.groupby(['STN', df['날짜'].dt.date]).agg({\n",
    "        'TA': ['mean', 'max', 'min'],\n",
    "        'RN': 'sum',\n",
    "        'WS': 'mean',\n",
    "        'HM': 'mean'\n",
    "    }).reset_index()\n",
    "    daily_data.columns = ['지점', '날짜', '평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']\n",
    "    return daily_data\n",
    "\n",
    "# 결측치 처리 함수\n",
    "def handle_missing_data(df, backup_station_data):\n",
    "    # '날짜' 열이 datetime 형식인지 확인 및 변환\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['날짜']):\n",
    "        df['날짜'] = pd.to_datetime(df['날짜'], errors='coerce')\n",
    "\n",
    "    # backup_station_data의 '날짜' 열도 datetime 형식으로 변환\n",
    "    if '날짜' in backup_station_data.columns and not pd.api.types.is_datetime64_any_dtype(backup_station_data['날짜']):\n",
    "        backup_station_data['날짜'] = pd.to_datetime(backup_station_data['날짜'], errors='coerce')\n",
    "    \n",
    "    # -99.0 및 -9.0을 결측치로 간주\n",
    "    df[['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']] = df[['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']].replace([-99.0, -9.0], np.nan)\n",
    "\n",
    "    missing_dates = df[df.isnull().any(axis=1)]['날짜']\n",
    "\n",
    "    for date in missing_dates:\n",
    "        backup_data = backup_station_data[backup_station_data['날짜'] == date]\n",
    "        if not backup_data.empty:\n",
    "            for col in ['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']:\n",
    "                df.loc[df['날짜'] == date, col] = backup_data[col].values[0]\n",
    "        else:\n",
    "            # 다른 연도의 같은 날짜 평균값으로 대체\n",
    "            same_day_data = df[(df['날짜'].dt.month == date.month) & (df['날짜'].dt.day == date.day)]\n",
    "            if not same_day_data.empty:\n",
    "                for col in ['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']:\n",
    "                    df.loc[df['날짜'] == date, col] = same_day_data[col].mean()\n",
    "\n",
    "    return df.interpolate()\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = datetime(2015, 3, 31)\n",
    "    end_date = datetime(2015, 4, 2)\n",
    "\n",
    "    try:\n",
    "        aws_data = download_aws_data(start_date, end_date)\n",
    "        asos_data = download_asos_data(start_date, end_date)\n",
    "\n",
    "        filtered_aws_data = filter_time_range(aws_data)\n",
    "        daily_aws_data = aggregate_daily_data(filtered_aws_data)\n",
    "\n",
    "        # ASOS 데이터도 일별 집계\n",
    "        daily_asos_data = aggregate_daily_data(asos_data)\n",
    "\n",
    "        # 데이터 확인 코드 추가\n",
    "        print(\"Daily AWS Data Columns:\", daily_aws_data.columns)\n",
    "        print(daily_aws_data.head())\n",
    "        print(\"Daily ASOS Data Columns:\", daily_asos_data.columns)\n",
    "        print(daily_asos_data.head())\n",
    "\n",
    "        # 결측치 보완\n",
    "        processed_data = handle_missing_data(daily_aws_data, daily_asos_data)\n",
    "\n",
    "        # 결과 저장\n",
    "        output_file = os.path.join(SAVE_PATH, \"sample3_weather_data.csv\")\n",
    "        processed_data.to_csv(output_file, index=False, encoding='cp949')\n",
    "        print(f\"File saved to: {os.path.abspath(output_file)}\")\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily AWS Data Columns: Index(['지점', '날짜', '평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)',\n",
      "       '평균 상대습도(%)'],\n",
      "      dtype='object')\n",
      "   지점          날짜  평균기온(℃)  최고기온(℃)  최저기온(℃)  일강수량(mm)  평균풍속(m/s)  평균 상대습도(%)\n",
      "0   2  2015-03-31      7.5      7.5      7.5       0.0        1.1        56.6\n",
      "1   2  2015-04-01     11.5     11.5     11.5       0.5        0.2        94.5\n",
      "2   2  2015-04-02      3.8      3.8      3.8       0.0        0.9        83.4\n",
      "3   3  2015-03-31     16.8     16.8     16.8       0.0        2.9         NaN\n",
      "4   3  2015-04-01     17.0     17.0     17.0       0.0        0.4         NaN\n",
      "File saved to: F:\\박정현\\ML\\Mosquito\\sample3_weather_data.csv\n",
      "Data saved to F:/박정현/ML/Mosquito/sample3_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import io\n",
    "\n",
    "# API 설정\n",
    "API_KEY = 's5DFRYyOQqKQxUWMjlKi9g'\n",
    "AWS_URL = 'https://apihub.kma.go.kr/api/typ01/url/awsh.php'\n",
    "ASOS_URL = 'https://apihub.kma.go.kr/api/typ01/url/kma_sfctm2.php'\n",
    "SAVE_PATH = 'F:/박정현/ML/Mosquito/'\n",
    "\n",
    "# DMS 시간 필터링: 전일 19시 ~ 당일 5시\n",
    "def filter_time_range(df, start_time='19:00', end_time='05:00'):\n",
    "    df.rename(columns={df.columns[0]: 'YYMMDDHHMI'}, inplace=True)\n",
    "    df['시간'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M')\n",
    "    df['시간'] = df['시간'].dt.strftime('%H:%M')  # 시간만 문자열로 추출\n",
    "\n",
    "    return df[(df['시간'] >= start_time) | (df['시간'] <= end_time)]\n",
    "\n",
    "# AWS 데이터 다운로드 함수\n",
    "def download_aws_data(start_date, end_date):\n",
    "    data_frames = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        params = {\n",
    "            'authKey': API_KEY,\n",
    "            'tm': current_date.strftime('%Y%m%d%H%M'),  # 시간 포함\n",
    "            'var': '0',  # 모든 필요한 데이터 요청\n",
    "            'stn': '0'  # 특정 관측소 요청\n",
    "        }\n",
    "\n",
    "        response = requests.get(AWS_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            raw_text = response.text\n",
    "            raw_data = response.text\n",
    "            df = pd.read_csv(io.StringIO(raw_data), sep='\\s+', comment='#', skip_blank_lines=True)\n",
    "            # 열 이름 확인 후 재설정\n",
    "            if len(df.columns) == 10:\n",
    "                df.columns = ['YYMMDDHHMI', 'STN', 'TA', 'WD', 'WS', 'RN_DAY', 'RN_HR1', 'HM', 'PA', 'PS']\n",
    "            data_frames.append(df)\n",
    "\n",
    "            for df in data_frames:\n",
    "                df[['YYMMDDHHMI', 'STN', 'TA', 'WD', 'WS', 'RN_DAY', 'RN_HR1', 'HM', 'PA', 'PS']] = df[['YYMMDDHHMI', 'STN', 'TA', 'WD', 'WS', 'RN_DAY', 'RN_HR1', 'HM', 'PA', 'PS']].replace(-99, np.nan)\n",
    "        else:\n",
    "            print(f\"Failed to fetch AWS data for {current_date}: {response.status_code}\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    if data_frames:\n",
    "        return pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"No AWS data available for the given date range\")\n",
    "\n",
    "# ASOS 데이터 다운로드 함수\n",
    "# \n",
    "    data_frames = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        params = {\n",
    "            'authKey': API_KEY,\n",
    "            'tm': current_date.strftime('%Y%m%d%H%M'),  # 시간 포함\n",
    "            'stn': 108  # 특정 관측소 요청\n",
    "        }\n",
    "\n",
    "        response = requests.get(ASOS_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            raw_text = response.text\n",
    "            raw_data = response.text\n",
    "            df = pd.read_csv(io.StringIO(raw_data), sep='\\s+', header=None, comment='#', skip_blank_lines=True)\n",
    "            # 필요한 열만 선택\n",
    "            if df.shape[1] >= 10:  # 최소 10개 이상의 열이 있을 경우\n",
    "                df = df.iloc[:, [0, 1, 11, 3, 15, 13]]  # 필요한 열 선택: YYMMDDHHMI, STN, TA, WS, RN, HM\n",
    "                df.columns = ['YYMMDDHHMI', 'STN', 'TA', 'WS', 'RN', 'HM']\n",
    "                # '날짜' 열 추가\n",
    "                df['날짜'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M').dt.date\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected number of columns in ASOS data for {current_date}\")\n",
    "            data_frames.append(df)\n",
    "        else:\n",
    "            print(f\"Failed to fetch ASOS data for {current_date}: {response.status_code}\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    if data_frames:\n",
    "        return pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"No ASOS data available for the given date range\")\n",
    "\n",
    "# 일 단위 변환 함수\n",
    "def aggregate_daily_data(df):\n",
    "    df['날짜'] = pd.to_datetime(df['YYMMDDHHMI'], format='%Y%m%d%H%M')\n",
    "    daily_data = df.groupby(['STN', df['날짜'].dt.date]).agg({\n",
    "        'TA': ['mean', 'max', 'min'],\n",
    "        'RN_HR1': 'sum',\n",
    "        'WS': 'mean',\n",
    "        'HM': 'mean'\n",
    "    }).reset_index()\n",
    "    daily_data.columns = ['지점', '날짜', '평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']\n",
    "    return daily_data\n",
    "\n",
    "# 결측치 처리 함수\n",
    "def handle_missing_data(df, backup_station_data):\n",
    "    # '날짜' 열이 datetime 형식인지 확인 및 변환\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['날짜']):\n",
    "        df['날짜'] = pd.to_datetime(df['날짜'], errors='coerce')\n",
    "\n",
    "    # backup_station_data의 '날짜' 열도 datetime 형식으로 변환\n",
    "    if '날짜' in backup_station_data.columns and not pd.api.types.is_datetime64_any_dtype(backup_station_data['날짜']):\n",
    "        backup_station_data['날짜'] = pd.to_datetime(backup_station_data['날짜'], errors='coerce')\n",
    "    \n",
    "    # -99.0 및 -9.0을 결측치로 간주\n",
    "    df[['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']] = df[['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']].replace(-99, np.nan)\n",
    "\n",
    "    missing_dates = df[df.isnull().any(axis=1)]['날짜']\n",
    "\n",
    "    for date in missing_dates:\n",
    "        backup_data = backup_station_data[backup_station_data['날짜'] == date]\n",
    "        if not backup_data.empty:\n",
    "            for col in ['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']:\n",
    "                df.loc[df['날짜'] == date, col] = backup_data[col].values[0]\n",
    "        else:\n",
    "            # 다른 연도의 같은 날짜 평균값으로 대체\n",
    "            same_day_data = df[(df['날짜'].dt.month == date.month) & (df['날짜'].dt.day == date.day)]\n",
    "            if not same_day_data.empty:\n",
    "                for col in ['평균기온(℃)', '최고기온(℃)', '최저기온(℃)', '일강수량(mm)', '평균풍속(m/s)', '평균 상대습도(%)']:\n",
    "                    df.loc[df['날짜'] == date, col] = same_day_data[col].mean()\n",
    "\n",
    "    return df.interpolate()\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = datetime(2015, 3, 31)\n",
    "    end_date = datetime(2015, 4, 2)\n",
    "\n",
    "    aws_data = download_aws_data(start_date, end_date)\n",
    "\n",
    "    filtered_aws_data = filter_time_range(aws_data)\n",
    "    daily_aws_data = aggregate_daily_data(filtered_aws_data)\n",
    "\n",
    "    # 데이터 확인 코드 추가\n",
    "    print(\"Daily AWS Data Columns:\", daily_aws_data.columns)\n",
    "    print(daily_aws_data.head())\n",
    "        \n",
    "\n",
    "    # 결과 저장\n",
    "    output_file = os.path.join(SAVE_PATH, \"sample3_weather_data.csv\")\n",
    "    daily_aws_data.to_csv(output_file, index=False, encoding='cp949')\n",
    "    print(f\"File saved to: {os.path.abspath(output_file)}\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
